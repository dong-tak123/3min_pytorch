{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch07. 순차적인 데이터를 처리하는 RNN",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bufrVYZbVPdN"
      },
      "source": [
        "#7.1 RNN 개요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg95nXqpVPZx"
      },
      "source": [
        "- 일반적인 신경망이나 CNN은 시간의 개념이 없음..\n",
        "- 컴퓨터가 글을 쓰고 이해하려면 **순서**가 중요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDmPBDLOVffL"
      },
      "source": [
        "**RNN의 작동 방식**\n",
        "\n",
        "- RNN은 시계열 데이터의 정보를 하나씩 입력받을 때마다 여태껏 입력받은 벡터를 종학하여 **은닉 벡터**를 만들어낸다.\n",
        "- 결국, **마지막 은닉 벡터**는 배열 속 모든 벡터의 내용을 압축한 벡터가 된다..\n",
        "- ex) LSTM, GRU.. -> 언어 모델링, 텍스트 감정 분석, 기계 번역.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoibH4IJVPXC"
      },
      "source": [
        "#7.2 영화 리뷰 감정 분석\n",
        "\n",
        "- 영화 리뷰를 RNN을 이용해서 내용 압축\n",
        "- 압축된 리뷰에 대한 긍정/부정을 판단하는 분류 모델 생성\n",
        "    - **워드 임베딩** : 언어의 최소단위인 토큰을 벡터 형태로 변환하는 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVq23f7xVPUI"
      },
      "source": [
        "##7.2.1 자연어 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDoAlLcEQTaw"
      },
      "source": [
        "#토치텍스트 사용..\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data, datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIoUdNIwWdVD",
        "outputId": "157ba960-070c-4915-ce72-38e892361134"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", DEVICE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkKxNgJWgRC"
      },
      "source": [
        "###IMDB 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXH-I83xWkoB",
        "outputId": "a8b363e9-cf02-4158-fd94-0dd63abac3dd"
      },
      "source": [
        "# 데이터 로딩하기\n",
        "print(\"데이터 로딩중...\")\n",
        "\n",
        "#sequential : 순차적인지..\n",
        "#batch_first : 입력 텐서의 첫번째 차원값을 batch_size로 지정..\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로딩중...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGPOZJLVWpRJ",
        "outputId": "a9af0a1c-7d63-47ad-f2d3-d25209d34a41"
      },
      "source": [
        "#테스트 세트 지정..\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:02<00:00, 39.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM8AfO67X-Qt"
      },
      "source": [
        "단어사전 만들기\n",
        "- 최소 5회 이상 나온 단어들만..\n",
        "- 이하는 unk으로 대체.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htzqqqGnX5fN"
      },
      "source": [
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t09p44gYIW3"
      },
      "source": [
        "검증세트는 따로 만들어야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biiTUZ67YGTl"
      },
      "source": [
        "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "\n",
        "# 배치크기만큼 배치 생성하는 반복자 생성..\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGKfqEbSYMEm"
      },
      "source": [
        "vocab_size = len(TEXT.vocab)        #단어사전 크기\n",
        "n_classes = 2                       #레이블 수"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNCsmp5iYZyp"
      },
      "source": [
        "데이터셋 분리 결과 확인.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4wRQpBrYTS5",
        "outputId": "8733d7d7-31ac-463e-c704-48a97fd896a3"
      },
      "source": [
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33JZXaaYgP3"
      },
      "source": [
        "##7.2.2 RNN 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jJzXf_Yc5n"
      },
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        print(\"Building Basic GRU model...\")\n",
        "        self.n_layers = n_layers        #층수\n",
        "        #단어 임베딩..(단어사전크기, 임베딩 후 차원)\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        #은닉차원\n",
        "        self.hidden_dim = hidden_dim\n",
        "        #드롭아웃 비율..\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        #일반적인 RNN은 그레이디언트 폭주/소실 문제로 인해 사용 안함.\n",
        "        #이를 보완한 GRU 사용\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        \n",
        "        #마지막 신경망 통과..\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)   #단어 임베딩된 x\n",
        "        h_0 = self._init_state(batch_size=x.size(0))        #첫번째 가중치 텐서..\n",
        "\n",
        "        #x에 모든 은닉벡터를 모아놓았다..\n",
        "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "\n",
        "        #마지막 은닉벡터만 가져온다..\n",
        "        #모든 벡터에 대한 정보가 담김..\n",
        "        h_t = x[:,-1,:]\n",
        "\n",
        "        #드롭아웃..\n",
        "        self.dropout(h_t)\n",
        "        #신경망을 통과시켜 결과 확인..\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data       #첫번째 가중치 텐서를 추출..\n",
        "        #첫 가중치 텐서 크기만큼의 0 텐서를 반환.\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6thAnG-qYk9b"
      },
      "source": [
        "훈련함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAcPbYg2YoXs"
      },
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()   #훈련모드\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)    #모델 예측..\n",
        "        loss = F.cross_entropy(logit, y)        #손실..\n",
        "        loss.backward()     #역전파..\n",
        "        optimizer.step()    #다음스텝..."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLWnaC3VYqGT"
      },
      "source": [
        "평가함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQfHgScQYpnk"
      },
      "source": [
        "def evaluate(model, val_iter):\n",
        "    model.eval()    #평가모드\n",
        "    corrects, total_loss = 0, 0\n",
        "\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "\n",
        "        logit = model(x)        #예측..\n",
        "\n",
        "        #손실 구하기,,\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()   #손실 총 합 계산\n",
        "\n",
        "        #예측의 값이 제일 큰 놈의 인덱스가 레이블과 같으면 corrects를 1 증가\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "\n",
        "    avg_loss = total_loss / size                #평균손실..\n",
        "    avg_accuracy = 100.0 * corrects / size      #정답률..\n",
        "    return avg_loss, avg_accuracy"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ6OCY_fYuIc"
      },
      "source": [
        "모델 및 최적화함수 객체 생성\n",
        "- Adam 최적화함수 사용 (국룰)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajm7y0EgYtQ4",
        "outputId": "88cd63bc-bc25-4814-ffdb-c887c6649004"
      },
      "source": [
        "#은닉벡터 256차원.. 임베딩된 토큰 128차원..\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Basic GRU model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByrzJ3RwY7ol"
      },
      "source": [
        "###학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H40jwC5kY0bP",
        "outputId": "9583c404-16c9-428e-bda5-c116c7edb9a0"
      },
      "source": [
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
        "    \n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[이폭: 1] 검증 오차: 0.69 | 검증 정확도:49.52\n",
            "[이폭: 2] 검증 오차: 0.70 | 검증 정확도:49.36\n",
            "[이폭: 3] 검증 오차: 0.69 | 검증 정확도:54.56\n",
            "[이폭: 4] 검증 오차: 0.63 | 검증 정확도:62.88\n",
            "[이폭: 5] 검증 오차: 0.36 | 검증 정확도:84.60\n",
            "[이폭: 6] 검증 오차: 0.33 | 검증 정확도:85.46\n",
            "[이폭: 7] 검증 오차: 0.41 | 검증 정확도:84.88\n",
            "[이폭: 8] 검증 오차: 0.42 | 검증 정확도:86.08\n",
            "[이폭: 9] 검증 오차: 0.41 | 검증 정확도:85.18\n",
            "[이폭: 10] 검증 오차: 0.45 | 검증 정확도:86.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRVXxURBZGXq"
      },
      "source": [
        "###평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfm7gE8_ZDxh",
        "outputId": "df34b988-08cd-42b2-a2f0-f62573e07729"
      },
      "source": [
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 오차:  0.34 | 테스트 정확도: 85.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHKG92i0f4Ga"
      },
      "source": [
        "#7.3 Seq2Seq 기계 번역"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYXP76anf8ZB"
      },
      "source": [
        "- 문장을 다른 문장으로 번역해주는 모델\n",
        "- 여기서는 \"hello\"를 \"hola\"로 번역하는 미니 Seq2Seq 모델을 만들자.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf-q9nHwgFyR"
      },
      "source": [
        "##7.3.1 Seq2Seq 개요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2aAY2KgHwX"
      },
      "source": [
        "- 각 자 다른 역할을 하는 두 개의 RNN을 이어붙힌 모델\n",
        "- 인코더 & 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rmkCbR8gPG-"
      },
      "source": [
        "##7.3.2 인코더\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF2WHo6FgSSl"
      },
      "source": [
        "- 원문의 내용을 학습하는 RNN\n",
        "- 압축된 텐서(마지막 토큰의 은닉벡터)는 원문의 뜻과 내용을 압축하고 있다고 해서 **문맥 벡터**라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE3-IybpghBc"
      },
      "source": [
        "##7.3.3 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JubqfxKgiV7"
      },
      "source": [
        "- 인코더에서 원문 문맥 벡터를 이어받아 번역문 속의 토큰을 차례대로 예상\n",
        "- 디코더는 번역문의 토큰을 출력할 때 **인코더로부터 정보를 전달 받아야함**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTA0YQn4gwoU"
      },
      "source": [
        "##7.3.4 Seq2Seq 모델 구현하기\n",
        "\n",
        "- 인코더가 문맥벡터 생성\n",
        "- 디코더가 그걸 받아서 번역문 예측\n",
        "- 실제 번역문 사이의 오차를 줄여나가는 방식으로 작동.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLZc7-D1hHDV"
      },
      "source": [
        "여기서는 미니 Seq2Seq이니까 단어임베딩이 아닌 **캐릭터임베딩**실시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUevb1mhgiCP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBR2h8ChhPkf"
      },
      "source": [
        "아스키코드로 임베딩.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beNUQ4KIhEJh",
        "outputId": "fb90c8e4-58a9-4c10-93cd-f72323cfcb51"
      },
      "source": [
        "vocab_size = 256  # 총 아스키 코드 개수\n",
        "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
        "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
        "print(\"hello -> \", x_)\n",
        "print(\"hola  -> \", y_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello ->  [104, 101, 108, 108, 111]\n",
            "hola  ->  [104, 111, 108, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acTgwwAvhTLv"
      },
      "source": [
        "#텐서로 변환..\n",
        "x = torch.LongTensor(x_)\n",
        "y = torch.LongTensor(y_)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW7C-dTrhV_h"
      },
      "source": [
        "###모델 생성\n",
        "\n",
        "- 티쳐포싱 사용\n",
        "    - 원래 디코더가 예측한 토큰을 다음 반복에서 입력될 토큰으로 갱신해야함\n",
        "    - BUT, 학습되지 않은 상태의 모델은 잘못된 예측토큰을 입력할 가능성이 높다..\n",
        "    - 이를 방지하기위해 **티쳐포싱**을 사용한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlfyHXohXkW"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_size = hidden_size      #은닉차원..\n",
        "        #임베딩층..\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.encoder = nn.GRU(hidden_size, hidden_size)     #인코더..\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size)     #디코더..\n",
        "        self.project = nn.Linear(hidden_size, vocab_size)   #일반신경망..\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 인코더에 들어갈 입력\n",
        "        initial_state = self._init_state()\n",
        "        #캐릭터 임베딩..\n",
        "        embedding = self.embedding(inputs).unsqueeze(1)\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        #encoder_state : 문맥 벡터..\n",
        "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
        "\n",
        "        # 디코더에 들어갈 입력\n",
        "        decoder_state = encoder_state\n",
        "        #디코더에 문장시작을 알리기 위해 0으로 설정..\n",
        "        decoder_input = torch.LongTensor([0])\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        outputs = []\n",
        "        \n",
        "        for i in range(targets.size()[0]):\n",
        "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
        "            #결괏값을 다시 디코더에 넣음..\n",
        "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
        "            #신경망으로 예측..\n",
        "            projection = self.project(decoder_output)\n",
        "            #예측값 append\n",
        "            outputs.append(projection)\n",
        "            \n",
        "            #티처 포싱(Teacher Forcing) 사용\n",
        "            #직접적으로 디코더를 위한 입력토큰 갱신\n",
        "            decoder_input = torch.LongTensor([targets[i]])\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze()\n",
        "        return outputs\n",
        "    \n",
        "    #초기 가중치 크기 지정 함수..\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyfGV9-ehbfM"
      },
      "source": [
        "모델 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgMRfvtFhdlJ"
      },
      "source": [
        "seq2seq = Seq2Seq(vocab_size, 16)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv_IZ5N1heD1"
      },
      "source": [
        "필요한 객체 생성.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLQs1s8XhlpD"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()       #크로스 엔트로피 오차 구하는 객체\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)     #최적화 알고리즘 객체"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdUb2Qalhx1O"
      },
      "source": [
        "###모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75mhggodhnSd",
        "outputId": "0f13793f-0d91-499a-d650-c4360b5365fe"
      },
      "source": [
        "log = []\n",
        "for i in range(1000):\n",
        "    prediction = seq2seq(x, y)          #예측..\n",
        "    loss = criterion(prediction, y)     #손실 계산..\n",
        "    optimizer.zero_grad()               #기울기 계산 시작한다..\n",
        "    loss.backward()     #역전파..\n",
        "    optimizer.step()    #다음 스텝..\n",
        "\n",
        "    #손실값을 저장..\n",
        "    loss_val = loss.data        \n",
        "    log.append(loss_val)\n",
        "\n",
        "    #백번째 에포크 마다 실행..\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
        "        #예측값을 가지고 확인해보자..\n",
        "        _, top1 = prediction.data.topk(1, 1)\n",
        "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 반복:0 오차: 5.411283016204834\n",
            "['K', 'V', 'f', 'a']\n",
            "\n",
            " 반복:100 오차: 2.004889488220215\n",
            "['h', 'o', 'a', 'a']\n",
            "\n",
            " 반복:200 오차: 0.5124512314796448\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:300 오차: 0.26142051815986633\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:400 오차: 0.16455115377902985\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:500 오차: 0.11463146656751633\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:600 오차: 0.08581574261188507\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:700 오차: 0.06734844297170639\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:800 오차: 0.05459779500961304\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:900 오차: 0.045322805643081665\n",
            "['h', 'o', 'l', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPaVaTN_h5m-"
      },
      "source": [
        "오차 확인.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xjG4Kr-Oh78T",
        "outputId": "904ebfdc-e636-49c4-b867-85deba1cc8f4"
      },
      "source": [
        "plt.plot(log)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
