{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#참조\n",
        "\n",
        "[Thanks to..](https://deep-learning-study.tistory.com/376)\n",
        "\n",
        "[AlexNet paper](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)"
      ],
      "metadata": {
        "id": "wyjiweQpe7Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모듈 불러오기"
      ],
      "metadata": {
        "id": "C3WphAwFSvUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E6sFCRjuQZ96"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F         #cross_entropy\n",
        "import torch.nn.init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(1109)\n",
        "\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(1109)"
      ],
      "metadata": {
        "id": "90fBDb3RS68C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 설계\n",
        "\n",
        "CONV1 - MAX POOL1 - NORM1 - CONV2 - MAXPOOL2 - NORM2 - CONV3 - CONV4 - CONV5 - MAXPOOL3 - FC6 - FC7 - FC8\n",
        "\n",
        "- NORM1, 2 모두 Response-normalization layer\n",
        "    - 측면 억제(강한 자극이 주변의 약한 자극을 전달하는 것을 막는 것)의 형태로 구현됨\n",
        "    - ex) 헤르만 격자..\n",
        "- 현재는 batch normalization이 쓰인다"
      ],
      "metadata": {
        "id": "3fWJTKpvTGQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구체적인 설명\n",
        "\n",
        "**Convolution**\n",
        "1. CONV1 : 96 (11*11) filters with stride 4\n",
        "    - ReLU()\n",
        "    - MAX POOL1 : (3*3) filters at stride 2\n",
        "        - overlapping max pooling\n",
        "    - NORM1\n",
        "        - local response normalization\n",
        "\n",
        "\n",
        "2. Conv2 : 256 (5*5) filters at stride 1, pad 2\n",
        "    - ReLU()\n",
        "    - MAX POOL2 : (3*3) filters at stride 2\n",
        "        - overlapping max pooling\n",
        "    - NORM2\n",
        "        - local response normalization\n",
        "\n",
        "3. CONV3 : 384 (3*3) filters at stride 1, pad 2\n",
        "    - ReLU()\n",
        "4. CONV4 : 384 (3*3) filters at stride 1, pad 2\n",
        "    - ReLU()\n",
        "5. CONV5 : 256 (3*3) filters at stride 1, pad 2\n",
        "    - ReLU()\n",
        "    - MAX POOL3 : (3*3) filters at stride 2\n",
        "        - overlapping max pooling\n",
        "\n",
        "**Fully Connected**\n",
        "6. FC6 : 4096 neurons    (**Use Dropout(0.5)**)\n",
        "    - ReLU()\n",
        "7. FC7 : 4096 neurons    (**Use Dropout(0.5)**)\n",
        "    - ReLU()\n",
        "8. FC8 : 1000 neurons  (number of classes)\n",
        "    - softmax()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "데이터셋은 ImageNet 데이터의 부분집합으로 하고, 1000개의 클래스를 가져온다"
      ],
      "metadata": {
        "id": "BO1dmwZOTfb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight Initialization**\n",
        "\n",
        "- $N(0, (0.01)^2)$ 로 초기화\n",
        "- 2, 4, 5번째 conv와 fc layer는 bias를 1로 초기화 (prevent Dying ReLU)"
      ],
      "metadata": {
        "id": "E02XfZZgjh-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예전에는 GPU 성능의 한계 때문에 두 개의 GPU를 공유하면서 학습하였다"
      ],
      "metadata": {
        "id": "gtrGyUVdWcpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            #CONV1  (b, 96, 55, 55)\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4,),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  #BN으로 대체\n",
        "\n",
        "            #CONV2  (b, 256, 13, 13)\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  #BN으로 대체\n",
        "            \n",
        "            #CONV3  (b, 384, 13, 13)\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #CONV4  (b, 384, 13, 13)\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #CONV5  (b, 384, 6, 6)\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            #FC6\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(384*6*6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #FC7\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #FC8\n",
        "            nn.Linear(4096, 1000)\n",
        "        )\n",
        "\n",
        "        self.init_bias()\n",
        "    \n",
        "    def init_bias(self):\n",
        "        for layer in self.conv:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "\n",
        "            #conv2, 4, 5는 bias를 1로 초기화\n",
        "            nn.init.constant_(self.conv[4].bias, 1)\n",
        "            nn.init.constant_(self.conv[10].bias, 1)\n",
        "            nn.init.constant_(self.conv[12].bias, 1)\n",
        "        \n",
        "        for layer in self.fc:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 1)        #prevent Dying ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(-1, 256*6*6)     #flatten\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "aHO_ZFdni0_o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성"
      ],
      "metadata": {
        "id": "7uRF7AOdoMI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = AlexNet().to(device)"
      ],
      "metadata": {
        "id": "gxug3QsDoLVP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss, Optimizer 설정\n",
        "\n",
        "- Loss : cross_entropy\n",
        "- Optimizer : SGD momentum with 0.9"
      ],
      "metadata": {
        "id": "eNVk0qTimDZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**하이퍼파라미터 설정**"
      ],
      "metadata": {
        "id": "zf7GU6LlnxX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 90\n",
        "BATCH_SIZE = 128\n",
        "MOMENTUM = 0.9\n",
        "LR_DECAY = 0.0005\n",
        "LR_INIT = 0.01"
      ],
      "metadata": {
        "id": "rmNFY2Z4nbS5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer 구현**"
      ],
      "metadata": {
        "id": "O4nezxJtn1Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(\n",
        "    params = alexnet.parameters(),\n",
        "    lr = LR_INIT,\n",
        "    momentum = MOMENTUM,\n",
        "    weight_decay = LR_DECAY\n",
        ")"
      ],
      "metadata": {
        "id": "P9VTUAljl691"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LR scheduler 구현**\n",
        "\n",
        "- 30step 마다 0.1씩 감소"
      ],
      "metadata": {
        "id": "L3jl3PmMpFI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "PjKTYjf3n_OM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "6qpaxr96pygZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 dataloader, X, y는 구현되지 않은 상태"
      ],
      "metadata": {
        "id": "JBDUoHMDqHWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    lr_scheduler.step()     #학습률 조정\n",
        "    for X, y in dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        output = alexnet(X)     #score확인\n",
        "        loss = F.cross_entropy(output, y)       #loss 계산\n",
        "\n",
        "        #parameter stepup\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer"
      ],
      "metadata": {
        "id": "WwvaulBlpjLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#혼자 구현 시도해 본 결과.."
      ],
      "metadata": {
        "id": "XlPNe2sroyky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#초기화하기가 너무 더럽다..\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        #CONV1  (b, 96, 55, 55)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "            nn.BatchNorm2d(),         #BN으로 대체\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        )\n",
        "\n",
        "        #CONV2  (b, 256, 13, 13)\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, pad=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "            nn.BatchNorm2d(),         #BN으로 대체\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        )\n",
        "\n",
        "        #CONV3  (b, 384, 13, 13)\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, pad=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        #CONV4  (b, 384, 13, 13)\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, pad=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        #CONV5  (b, 384, 6, 6)\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, pad=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),    #overlapping max pooling\n",
        "        )\n",
        "\n",
        "        #FC6\n",
        "        self.fc6 = nn.Sequential(\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(384*6*6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        #FC7\n",
        "        self.fc7 = nn.Sequential(\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        #FC8\n",
        "        self.fc8 = nn.Linear(4096, 1000)\n",
        "        \n",
        "        self.init_bias()\n",
        "    \n",
        "    def init_bias(self):\n"
      ],
      "metadata": {
        "id": "Z34nVdEFTEXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}